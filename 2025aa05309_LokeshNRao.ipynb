{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6230de4b-0161-4676-8ff8-f95e4f451b0e",
   "metadata": {},
   "source": [
    "# Machine Learning Assignment 2\n",
    "## Heart Disease Prediction \n",
    "\n",
    "**Objective:** To train and evaluate machine learning models that can classify whether a patient has heart disease (target variable) based on input health measurements. \n",
    "\n",
    "**Metric:** \n",
    "1. Accuracy\n",
    "2. AUC Score\n",
    "3. Precision\n",
    "4. Recall\n",
    "5. F1 Score\n",
    "6. Matthews Correlation Coeffi cient (MCC Score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ae91e6e0-f738-4023-96a7-972cadf3acc5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Libraries imported successfully.\n"
     ]
    }
   ],
   "source": [
    "# Import core data manipulation and numerical computation libraries\n",
    "import pandas as pd  # For loading and manipulating tabular data\n",
    "import numpy as np   # For numerical operations and array handling\n",
    "import matplotlib.pyplot as plt  # For creating visualizations and plots\n",
    "import seaborn as sns  # For enhanced statistical visualizations\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Import machine learning libraries from scikit-learn\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV  # train_test_split: splits data into training and testing sets, GridSearchCV: performs hyperparameter tuning\n",
    "from sklearn.linear_model import LinearRegression, Ridge, Lasso  # Linear regression models: LinearRegression (basic), Ridge (L2 regularization), Lasso (L1 regularization)\n",
    "from sklearn.preprocessing import PolynomialFeatures, StandardScaler, MinMaxScaler  # PolynomialFeatures: creates polynomial and interaction features, StandardScaler: normalizes features to mean=0, std=1\n",
    "from sklearn.pipeline import Pipeline  # Creates a sequence of data transformations and model fitting steps\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.naive_bayes import GaussianNB, MultinomialNB\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "# Configure visualization settings for consistent plot appearance\n",
    "sns.set_style('whitegrid')  # Sets seaborn plot style with white background and grid lines\n",
    "plt.rcParams['figure.figsize'] = (12, 6)  # Sets default figure size to 12 inches wide by 6 inches tall\n",
    "\n",
    "print(\"Libraries imported successfully.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d107307f-f7a3-4bd9-b38e-23d3257b60f5",
   "metadata": {},
   "source": [
    "###  Exploratory Data Analysis (EDA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3be703a2-97b1-463c-9eb1-1decc9739414",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train shape: (1025, 14)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>sex</th>\n",
       "      <th>cp</th>\n",
       "      <th>trestbps</th>\n",
       "      <th>chol</th>\n",
       "      <th>fbs</th>\n",
       "      <th>restecg</th>\n",
       "      <th>thalach</th>\n",
       "      <th>exang</th>\n",
       "      <th>oldpeak</th>\n",
       "      <th>slope</th>\n",
       "      <th>ca</th>\n",
       "      <th>thal</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>52</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>125</td>\n",
       "      <td>212</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>168</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>53</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>140</td>\n",
       "      <td>203</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>155</td>\n",
       "      <td>1</td>\n",
       "      <td>3.1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>70</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>145</td>\n",
       "      <td>174</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>125</td>\n",
       "      <td>1</td>\n",
       "      <td>2.6</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   age  sex  cp  trestbps  chol  fbs  restecg  thalach  exang  oldpeak  slope  \\\n",
       "0   52    1   0       125   212    0        1      168      0      1.0      2   \n",
       "1   53    1   0       140   203    1        0      155      1      3.1      0   \n",
       "2   70    1   0       145   174    0        1      125      1      2.6      0   \n",
       "\n",
       "   ca  thal  target  \n",
       "0   2     3       0  \n",
       "1   0     3       0  \n",
       "2   0     3       0  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "age           int64\n",
       "sex           int64\n",
       "cp            int64\n",
       "trestbps      int64\n",
       "chol          int64\n",
       "fbs           int64\n",
       "restecg       int64\n",
       "thalach       int64\n",
       "exang         int64\n",
       "oldpeak     float64\n",
       "slope         int64\n",
       "ca            int64\n",
       "thal          int64\n",
       "target        int64\n",
       "dtype: object"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Missing values (train):\n",
      "age         0\n",
      "sex         0\n",
      "cp          0\n",
      "trestbps    0\n",
      "chol        0\n",
      "fbs         0\n",
      "restecg     0\n",
      "thalach     0\n",
      "exang       0\n",
      "oldpeak     0\n",
      "slope       0\n",
      "ca          0\n",
      "thal        0\n",
      "target      0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Importing the dataset:  Import Train data\n",
    "train_path = \"heart.csv\"\n",
    "train = pd.read_csv(train_path)\n",
    "\n",
    "\n",
    "# Rows and Column count ( no of samples and features with output in train data , without output and some other feature ommision  in test data)\n",
    "print(\"Train shape:\", train.shape)\n",
    "\n",
    "display(train.head(3))\n",
    "display(train.dtypes)\n",
    "\n",
    "# finding out any missing value to do the data cleansing (inputing the missing value)\n",
    "print(\"\\nMissing values (train):\")\n",
    "print(train.isna().sum().sort_values(ascending=False))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ad2d1c0b-06c1-4114-aca9-5f293148476c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Statistical Summary of Numeric Features ---\n",
      "               age          sex           cp     trestbps        chol  \\\n",
      "count  1025.000000  1025.000000  1025.000000  1025.000000  1025.00000   \n",
      "mean     54.434146     0.695610     0.942439   131.611707   246.00000   \n",
      "std       9.072290     0.460373     1.029641    17.516718    51.59251   \n",
      "min      29.000000     0.000000     0.000000    94.000000   126.00000   \n",
      "25%      48.000000     0.000000     0.000000   120.000000   211.00000   \n",
      "50%      56.000000     1.000000     1.000000   130.000000   240.00000   \n",
      "75%      61.000000     1.000000     2.000000   140.000000   275.00000   \n",
      "max      77.000000     1.000000     3.000000   200.000000   564.00000   \n",
      "\n",
      "               fbs      restecg      thalach        exang      oldpeak  \\\n",
      "count  1025.000000  1025.000000  1025.000000  1025.000000  1025.000000   \n",
      "mean      0.149268     0.529756   149.114146     0.336585     1.071512   \n",
      "std       0.356527     0.527878    23.005724     0.472772     1.175053   \n",
      "min       0.000000     0.000000    71.000000     0.000000     0.000000   \n",
      "25%       0.000000     0.000000   132.000000     0.000000     0.000000   \n",
      "50%       0.000000     1.000000   152.000000     0.000000     0.800000   \n",
      "75%       0.000000     1.000000   166.000000     1.000000     1.800000   \n",
      "max       1.000000     2.000000   202.000000     1.000000     6.200000   \n",
      "\n",
      "             slope           ca         thal       target  \n",
      "count  1025.000000  1025.000000  1025.000000  1025.000000  \n",
      "mean      1.385366     0.754146     2.323902     0.513171  \n",
      "std       0.617755     1.030798     0.620660     0.500070  \n",
      "min       0.000000     0.000000     0.000000     0.000000  \n",
      "25%       1.000000     0.000000     2.000000     0.000000  \n",
      "50%       1.000000     0.000000     2.000000     1.000000  \n",
      "75%       2.000000     1.000000     3.000000     1.000000  \n",
      "max       2.000000     4.000000     3.000000     1.000000  \n",
      "--- Dataset Info ---\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1025 entries, 0 to 1024\n",
      "Data columns (total 14 columns):\n",
      " #   Column    Non-Null Count  Dtype  \n",
      "---  ------    --------------  -----  \n",
      " 0   age       1025 non-null   int64  \n",
      " 1   sex       1025 non-null   int64  \n",
      " 2   cp        1025 non-null   int64  \n",
      " 3   trestbps  1025 non-null   int64  \n",
      " 4   chol      1025 non-null   int64  \n",
      " 5   fbs       1025 non-null   int64  \n",
      " 6   restecg   1025 non-null   int64  \n",
      " 7   thalach   1025 non-null   int64  \n",
      " 8   exang     1025 non-null   int64  \n",
      " 9   oldpeak   1025 non-null   float64\n",
      " 10  slope     1025 non-null   int64  \n",
      " 11  ca        1025 non-null   int64  \n",
      " 12  thal      1025 non-null   int64  \n",
      " 13  target    1025 non-null   int64  \n",
      "dtypes: float64(1), int64(13)\n",
      "memory usage: 112.2 KB\n",
      "None\n",
      "\n",
      "--- Missing Values ---\n",
      "age         0\n",
      "sex         0\n",
      "cp          0\n",
      "trestbps    0\n",
      "chol        0\n",
      "fbs         0\n",
      "restecg     0\n",
      "thalach     0\n",
      "exang       0\n",
      "oldpeak     0\n",
      "slope       0\n",
      "ca          0\n",
      "thal        0\n",
      "target      0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# === Display statistical summary of all features ===\n",
    "print(\"\\n--- Statistical Summary of Numeric Features ---\")\n",
    "print(train.describe())  # Shows count, mean, std, min, 25%, 50%, 75%, max for each numeric column\n",
    "\n",
    "# Display comprehensive information about the training dataset structure\n",
    "print(\"--- Dataset Info ---\")\n",
    "print(train.info())  # Shows column names, data types, non-null counts, and memory usage\n",
    "\n",
    "# Check for missing values in each column (important for data quality)\n",
    "print(\"\\n--- Missing Values ---\")\n",
    "print(train.isnull().sum())  # Returns count of null/NaN values per column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "652de451-b7d6-448b-83a1-02f1f8382bae",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Do feature engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "021457f0-c585-471a-a2c7-ab5f7c53b297",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "def feature_engineering(df, scaler=None, fit=True):\n",
    "    df = df.copy()\n",
    "\n",
    "    # Fill missing values\n",
    "    for col in df.columns:\n",
    "        if df[col].dtype == \"object\":\n",
    "            df[col] = df[col].fillna(df[col].mode()[0])\n",
    "        else:\n",
    "            df[col] = df[col].fillna(df[col].median())\n",
    "\n",
    "    # Create new features\n",
    "    df[\"chol_age_ratio\"] = df[\"chol\"] / df[\"age\"]\n",
    "    df[\"high_risk\"] = ((df[\"trestbps\"] > 140) & (df[\"chol\"] > 240)).astype(int)\n",
    "\n",
    "    if \"target\" in df.columns:\n",
    "        X = df.drop(\"target\", axis=1)\n",
    "        y = df[\"target\"]\n",
    "    else:\n",
    "        X = df\n",
    "        y = None\n",
    "\n",
    "    num_cols = X.select_dtypes(include=[\"int64\", \"float64\"]).columns\n",
    "\n",
    "    if fit:\n",
    "        scaler = StandardScaler()\n",
    "        X[num_cols] = scaler.fit_transform(X[num_cols])\n",
    "    else:\n",
    "        X[num_cols] = scaler.transform(X[num_cols])\n",
    "\n",
    "    return X, y, scaler\n",
    "\n",
    "\n",
    "X, y, scaler = feature_engineering(train, fit=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0c857c02-60ef-47a6-9466-51d69113a1cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Model training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "331c222e-d1d8-49c7-91de-8fb88a4b68d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y,\n",
    "    test_size=0.2,      # 20% for testing, 80% for training\n",
    "    random_state=42,    # same result every time\n",
    "    stratify=y          # keeps class balance\n",
    ")\n",
    "\n",
    "\n",
    "\n",
    "# Logistic Regression\n",
    "model_lr = LogisticRegression(max_iter=1000)\n",
    "model_lr.fit(X_train, y_train)\n",
    "y_pred_lr = model_lr.predict(X_test)\n",
    "\n",
    "# Decision Tree Classifier\n",
    "model_dt = DecisionTreeClassifier(random_state=42)\n",
    "model_dt.fit(X_train, y_train)\n",
    "y_pred_dt = model_dt.predict(X_test)\n",
    "\n",
    "# K-Nearest Neighbor (KNN)\n",
    "model_knn = KNeighborsClassifier(n_neighbors=5)\n",
    "model_knn.fit(X_train, y_train)\n",
    "y_pred_knn = model_knn.predict(X_test)\n",
    "\n",
    "# Naive Bayes (Gaussian)\n",
    "model_nb = GaussianNB()\n",
    "model_nb.fit(X_train, y_train)\n",
    "y_pred_nb = model_nb.predict(X_test)\n",
    "\n",
    "# Random Forest\n",
    "model_rf = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "model_rf.fit(X_train, y_train)\n",
    "y_pred_rf = model_rf.predict(X_test)\n",
    "\n",
    "#XGBoost\n",
    "model_xgb = XGBClassifier(use_label_encoder=False, eval_metric='logloss')\n",
    "model_xgb.fit(X_train, y_train)\n",
    "y_pred_xgb = model_xgb.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3a71c34a-46eb-4964-b77f-4419ac451234",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Evaluation Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d54e9d29-7e5c-4c46-a239-2ea01013458b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "===== Logistic Regression =====\n",
      "Accuracy : 80.98%\n",
      "AUC Score: 92.87%\n",
      "Precision: 76.19%\n",
      "Recall   : 91.43%\n",
      "F1 Score : 83.12%\n",
      "MCC Score: 63.09%\n",
      "\n",
      "===== Decision Tree =====\n",
      "Accuracy : 98.54%\n",
      "AUC Score: 98.57%\n",
      "Precision: 100.00%\n",
      "Recall   : 97.14%\n",
      "F1 Score : 98.55%\n",
      "MCC Score: 97.12%\n",
      "\n",
      "===== KNN =====\n",
      "Accuracy : 84.88%\n",
      "AUC Score: 95.65%\n",
      "Precision: 87.00%\n",
      "Recall   : 82.86%\n",
      "F1 Score : 84.88%\n",
      "MCC Score: 69.86%\n",
      "\n",
      "===== Naive Bayes =====\n",
      "Accuracy : 82.44%\n",
      "AUC Score: 90.15%\n",
      "Precision: 79.49%\n",
      "Recall   : 88.57%\n",
      "F1 Score : 83.78%\n",
      "MCC Score: 65.21%\n",
      "\n",
      "===== Random Forest =====\n",
      "Accuracy : 100.00%\n",
      "AUC Score: 100.00%\n",
      "Precision: 100.00%\n",
      "Recall   : 100.00%\n",
      "F1 Score : 100.00%\n",
      "MCC Score: 100.00%\n",
      "\n",
      "===== XGBoost =====\n",
      "Accuracy : 100.00%\n",
      "AUC Score: 100.00%\n",
      "Precision: 100.00%\n",
      "Recall   : 100.00%\n",
      "F1 Score : 100.00%\n",
      "MCC Score: 100.00%\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import (\n",
    "    accuracy_score, roc_auc_score,\n",
    "    precision_score, recall_score,\n",
    "    f1_score, matthews_corrcoef\n",
    ")\n",
    "\n",
    "\n",
    "models = {\n",
    "    \"Logistic Regression\": model_lr,\n",
    "    \"Decision Tree\": model_dt,\n",
    "    \"KNN\": model_knn,\n",
    "    \"Naive Bayes\": model_nb,\n",
    "    \"Random Forest\": model_rf,\n",
    "    \"XGBoost\": model_xgb\n",
    "}\n",
    "\n",
    "for name, model in models.items():\n",
    "    print(f\"\\n===== {name} =====\")\n",
    "    \n",
    "    y_pred = model.predict(X_test)\n",
    "    \n",
    "    # AUC needs probabilities\n",
    "    if hasattr(model, \"predict_proba\"):\n",
    "        y_prob = model.predict_proba(X_test)[:, 1]\n",
    "        auc = roc_auc_score(y_test, y_prob) * 100\n",
    "    else:\n",
    "        auc = None\n",
    "    \n",
    "    acc = accuracy_score(y_test, y_pred) * 100\n",
    "    prec = precision_score(y_test, y_pred) * 100\n",
    "    rec = recall_score(y_test, y_pred) * 100\n",
    "    f1 = f1_score(y_test, y_pred) * 100\n",
    "    mcc = matthews_corrcoef(y_test, y_pred) * 100\n",
    "\n",
    "    print(f\"Accuracy : {acc:.2f}%\")\n",
    "    print(f\"AUC Score: {auc:.2f}%\" if auc is not None else \"AUC Score: N/A\")\n",
    "    print(f\"Precision: {prec:.2f}%\")\n",
    "    print(f\"Recall   : {rec:.2f}%\")\n",
    "    print(f\"F1 Score : {f1:.2f}%\")\n",
    "    print(f\"MCC Score: {mcc:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b75b8e4f-5f4c-4629-b2a0-300ac9cb17be",
   "metadata": {},
   "source": [
    "#Saving the model as pkl file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "cc334d5a-d0d0-4c30-9998-c0c5fc2bec0d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All models saved as pickle files.\n"
     ]
    }
   ],
   "source": [
    "import joblib\n",
    "\n",
    "joblib.dump(model_lr,  \"logistic.pkl\")\n",
    "joblib.dump(model_dt,  \"decision_tree.pkl\")\n",
    "joblib.dump(model_knn, \"knn.pkl\")\n",
    "joblib.dump(model_nb,  \"naive_bayes.pkl\")\n",
    "joblib.dump(model_rf,  \"random_forest.pkl\")\n",
    "joblib.dump(model_xgb, \"xgboost.pkl\")\n",
    "joblib.dump(scaler, \"scaler.pkl\")\n",
    "\n",
    "print(\"All models saved as pickle files.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9020dd0b-dfb7-476e-911b-ab4dd9609f64",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
